---
layout:     post
title:      "What do LLMs need to Synthesize Correct Router Configurations"
subtitle:   " \"—— CoSynth 论文阅读笔记\""
date:       2024-10-22 19:44:00
author:     "wanqing"
header-img: "img/in-post/post.jpg"
catalog: true
tags:
    - 论文阅读笔记
---

> “Sometimes, I really miss her. ”

# What do LLMs need to Synthesize Correct Router Configurations?
https://doi.org/10.1145/ 3626111.3628194

#  **摘要**

1. 研究 是否大模型可以生成正确的网络配置，减少人工的手动修改。
2. 提出 “Verified Prompt Programming”
3. 结合 GPT-4和验证器（“verifiers” ）
4. 两个实验
    
    - 在单个路由器上翻译“Cisco” 到“Juniper”
    - 在多个路由器上实现“no-transit policy”
5. 定义 “leverage”  —— 自动提示词数量与人工提示词数量的比值
6. 实验结果
    
    - Cisco - Juniper ：10X
    - no-transit policy：6X

* * *

# 1. **Introduction**

1. LLMs在很多领域取得了成功
    
    - 写诗、通过法考
2. 很多领域有问题
    
    - 数学、字谜
3. 在写程序上也有一些成功的例子
    
    - “AlphaCode”
    - “CoPilot”
    - “Codex”
    - “Jigsaw”
    - …
4. 软件测试和调试助手
5. 我们的工作 —— 探索GPT4在生成路由器配置方面的能力
6. 我们的实验
    
    - 先证明了 只是依靠 GPT4 是低能的

* * *

1. 批评家嘲笑LLMs是随机鹦鹉“stochastic parrots”
    
    - 因为其是根据统计学模型（根据大语料库构建的）预测下一个词的
2. 我们的目标
    
    - 生成配置
    - 探索将 LLMs 和 其他的程序 APIs融合，从而理解程序语义 —— 变成一个随机猫头鹰 “stochastic owl”

* * *

1. 合理的方式1： 结合一个“a SAT solver or a model checker”
    
    - 验证器不能在没有规则的情况下，证明正确性
    - 验证器必须提供可操作的反馈
    - 我们发现LLM使用网络组件（单个路由器[11 - Using modularity to scale BGP control plane verification. SIGCOMM ’23, to appear. Association for Computing Machinery, 2023.]甚至路由器内的路由图[12 - A. Tang, S. K. R. Kakarla, R. Beckett, E. Zhai, M. Brown, T. Millstein, and G. Varghese. Campion: Debugging router configuration differences. SIGCOMM ’21, page 748–761, New York, NY, US, 2021. Association for Computing Machinery.]）的模块化验证反馈来纠正自己比使用整个网络更容易。

* * *

1. PP （“pair programming” ）
    
    - “GitHub CoPilot”
    - 人类和AI一起工作去实现一个程序
    - “prompt engineering.”  - 人工的初始化提示，人工的去纠错
    - “tuple (A, H )”
2. VPP（“Verified Prompt Programming” ）
    
    - “a triple (A, H, V )”
    - AI 人类 验证器
    - 验证器自动纠错
    - 验证器纠错几轮后，可能会放弃纠错
    - 然后人类去手动纠错
    - 从而，减少人费的力气 （假设）
        
        ## “reduced work hypothesis”
        

* * *

1. V-A间进行内部循环，验证器结果自动反馈给GPT4
2. 我们将验证器的反馈结果转为自然语言提示词 —— 通过“humanizer” ，然后交给GPT4
3. 当V确定配置是正确的，或者超过给定的时间限制时，输出作为 缓慢的人类手动循环的一部分的结果 给用户 “sends the output back to the user as part of the slow manual loop”
4. 检查/检验我们所做的减少人类工作量的假设（VPP vs PP）

* * *

1. 引入度量 - “leverage” - 衡量“verifier suite” （验证器套件）的影响 - 自动提示词的数量与人工提示词的数量之比
2. “as the ratio L of the number of automated prompts in Figure 2 to the number of human prompts.”
3. leverage 在相同实验的多次迭代中可能是不同的 - 因为LLM生成结果的随机性

* * *

1. 读者可能会认为衡量 leverage 的方式是 ： 衡量 H 到 （A,H），或者 H 到 （A,V,H）的提升
2. 但是，人类H的能力也是不同的
3. 所以，衡量VPP带来的改善更为自然
4. 假设图2中的每个自动更正都将由图1中的人工完成

* * *

1. L > 1 高
2. L = 1 低 - 配置正确也是重要的
3. 在这两个用例中，我们都通过GPT-4验证了配置，在开始不是明显的

* * *

1. 从配置生成扩展到一般情况
2. “Prompt programming” （相对于“prompt engineering” 说的 ）
3. 反映了api的使用和自动生成的反馈提示，这些提示可能更普遍有用
4. 网络配置是一个可以进行实验的非常简单的领域
5. “provide actionable localized feedback.”
    
    - “Campion”  A. Tang, S. K. R. Kakarla, R. Beckett, E. Zhai, M. Brown, T. Millstein, and G. Varghese. Campion: Debugging router configuration differences. SIGCOMM ’21, page 748–761, New York, NY, US, 2021. Association for Computing Machinery.
    - “Lightyear”  A. Tang, , R. Beckett, K. Jayaraman, T. Millstein, and G. Varghese. Lightyear: Using modularity to scale BGP control plane verification. SIGCOMM ’23, to appear. Association for Computing Machinery, 2023.

* * *

1. 验证 reduced work hypothesis 通过两个实验
    
    - “translating a config on a single router from Cisco to Juniper syntax”
    - “implementing a simple policy (“no transit") on a network of 6 routers.”
2. section2描述了“COSYNTH” 的系统组织
3. section3描述了描述translating a config on a single router from Cisco to Juniper syntax实验
4. section4描述implementing a simple policy (“no transit") on a network of 6 routers.实现
5. section5对比之前的工作

* * *

# 2. System Organization

1. 并没有建立COSYNTH
2. 当我们使用GPT-4时，我们无法访问API，因此手动模拟API调用并提示ChatGPT
3. 只是探索 GPT4 生成配置的能力

* * *

1. 两个验证器
    
    - 语法验证器 “Batfish”
    - 语义验证器 依据用例选择
    - 对于第二个用例，我们使用了第三个验证器，一个拓扑验证器（我们用Python编写的），因为我们发现GPT-4有时会错过向邻居宣布路由。
2. 用户提供精确的自然语言描述内容（“topology, routers, interfaces” ）和 期望实现的目标 （如：“the Cisco config and a request to translate it to Juniper” ）
3. “GPT-4 output” 先进入 “Batfish”
4. COSYNTH向GPT-4发送关于错误语句的反馈，“humanized" in natural language” —— 见 表 1
5. H - 作为 错误解析器 和 自然语言 翻译器

* * *

1. 语法错误都纠正完后（语法错误太多，直接punt给用户），进入“semantics verifier”
2. case1 “Campion”
3. case2 “Batfish’s symbolic route map analysis”
4. “Batfish’s symbolic route map analysis”  - 验证本地策略从而确保全局策略
5. 返回语义验证器的结果（humanized）给 GPT4
6. 有时候，GPT4在解决语义错误的同时引入语法错误
7. 就这样一直执行，执行很多轮后，结束（1. 通过语义验证 2. 次数太多 ）

* * *

1. “works with multiple routers”
2. ““Modularizer"”
3. 从一个精确的机器可读（我们使用JSON）的“模块”描述开始，（拓扑和连接）
4. Modularizer 输入是 “a sequence of Natural Language Prompts that describes the topology”
5. “e.g.,. Router R1 is connected to Router R2 via interface I 1 at R1 and I 2 at R2”

* * *

1. “modularizer” 给模型时间思考，分解复杂的提示词到简单的子提示词
2. “single shot prompting”  DeepLearning.AI. ChatGPT Prompt Engineering for Developers. [https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/ introduction](https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction), 2023.
    
    - “initial instruction prompts (IIP)” 初始指令提升
    - “IIP database”   - 由专家长久添加
    - eg. “Jigsaw”  N. Jain, S. Vaidyanath, A. Iyer, N. Natarajan, S. Parthasarathy, S. Rajamani, and R. Sharma. Jigsaw: Large language models meet program synthesis. In Proceedings of the 44th International Conference on Software Engineering, ICSE ’22, page 1219–1231, New York, NY, USA, 2022. Association for Computing Machinery.
    - 我们的 IIPs 由 指令 构成

* * *

# 3 Cisco to Juniper Translation

1. “Batfish”  - 语法错误
2. “Campion”  - 语义错误
    
    * * *
    

## 方法

1. 提供 思科配置 和 prompt
2. promt - “Translate the configuration into an equivalent Juniper configuration.”
3. GPT4最开始产生的结果具有很多错误
4. 然后我们使用 “"humanized"” 的来自验证器的反馈结果去反复纠正错误
5. 每个轮次结束重新使用验证器验证一遍配置
6. 在实验中，只关注 路由 和 转发 ， 忽视可能有的重要功能，比如“NTP servers”

* * *

1. “humanizer”  的 设计 （ 使用 “Python script” ）
2. 定义了4类配置错误
    
    - “Syntax errors” ： batfish 识别错误的 juniper 语法
    - “Structural mismatch/conflict”：指组件、连接或命名策略在原始配置中，但没有出现在翻译完的配置中（或者出现在转换中，但没有出现在原始配置中）。
        
        - eg:在原始配置中定义了BGP邻居，但是在转换过程中没有相应的邻居，就会出现路由连接不匹配的情况。Campion能够检测到这一点，并识别缺失或额外的项目。
    - “Attribute differences” :数字类型的属性在前后的配置中值不同
        
        - eg 两个接口间的OSPF链路开销(路由成本)不同。Campion检测这些并输出相应组件的属性。
    - “Policy behavior differences” ：当“route map” 或访问控制列表“access control list” 具有语义差异
        
        - Campion能够检测到这些差异，并为这些差异输出相关的策略名称、前缀和行。
    
    * * *
    
    1. 划分的两点道理
        
        - “syntax errors and structural mismatches” ：需要更早被发现和处理 因为它们可以掩盖 “attribute differences and policy behavior differences”
        - 不同类型的错误需要不同的人性化提示词，而相同类型的错误可以重用相似的提示词。
    2. 每种类型的错误都可以用公式提示词（“a formulaic prompt” ）进行总结，并根据Batfish或Campion报告的错误插入一些字段。

* * *

表1 - 斜体为 “Batfish and Campion” 生成的结果 ， 非斜体的为 a formulaic prompt 插入的部分 ， 共同形成了完整的提示词

1. “Batfish parse errors and warnings” 可以重用
2. “structural mismatches and attribute differences” 的提示生成是容易的
3. “Policy behavior differences”  生成是困难的，因为不总是清楚如何描述受影响的输入空间。
    
    - 选择给出一个具体例子的方法。

* * *

## “Experience and Results”

1. 例子 ： Batfish的网络example ，不超过GPT4的输入限制（“BGP, OSPF, prefix lists, and route maps” ）
2. 结果：GPT4修复错误的同时也引入了过去没有的新错误，甚至还会重新引入已经修复过的错误
3. 最终：可以完成翻译任务，通过 自动提示词 + 人工提示词
4. “Leverage”  - 在一个示例中，2个人工提示和20个自动提示， “Leverage”  = 10X
    
    - 在20个自动提示纠正周期中，有一些包含了小的语法纠正周期，不仅在开始时，而且在纠正语义错误之后。
    - 通过手动向GPT-4提供自动生成的提示来“模拟”每个API调用。

* * *

table2 展示了翻译中的某些错误，以及GPT-4是否能够使用自动生成的提示来修复这些错误

1. “Missing BGP local-as attribute”
2. “Missing/extra BGP routing policy”
3. “Different OSPF link attributes:”
4. “Setting wrong BGP MED value”
    
    - BGP路由策略转换没有更新BGP MED值。这是由于从原始Cisco配置中翻译“route map clauses” 时出现错误造成的
5. “Different Redistribution behavior into BGP”
    
    - 思科和Juniper格式处理路由重分配到BGP的方式不同。Juniper通常使用相同的路由策略来控制BGP路由的导入和导出，而Cisco配置为路由重新分配设置了单独的“route map” 。 - 需要找一个例子看看
    - Juniper配置重新分配了一些路由，而Cisco配置没有
    - 解决：向“policy” 中的多个位置添加“from bgp”条件。
    - GPT4不能解决这个问题  “does nothing”
6. “BGP prefix list issues” (Mondal 等, 2023, p. 192)
    
    - “ip prefix-list our-networks seq 5 permit 1.2.3.0/24 ge 24”
    - 当GPT4翻译上面的acl时，因为juniper没有ge 24语法，它会直接舍弃这个，从而导致匹配的前缀空间不同
    - 让GPT4修复这个问题时，它会产生不正确语法的现象,如下
        
        - “prefix-list our-networks { 1.2.3.0/24-32; }” (Mondal 等, 2023, p. 192)

* * *

# 4. Global Policies via Local Synthesis

1. 受Lightyear启发，使用GPT-4根据每个路由器的本地策略为给定的网络拓扑生成路由器配置，Lightyear通过验证局部不变量（“local invariants” ）来进行控制平面验证。
2. 范围限制在BGP

* * *

1. “semantic correctness,”
    
    - “a "topology" verifier”
        
        - 验证 GPT-4是否正确建立所有接口、声明BGP邻居和发布网络
    - “Batfish”  检查“prompts” 中定义的本地策略（“local policies” ）。使用输出去修正结果。

* * *

## 方法

1. 首先使用几个句子在初始提示中将任务指定给GPT
2. 目标：使网络遵循无中转政策（“no-transit policy” ），在这种政策下，没有两个ISP能够到达对方。但是，所有isp都应该能够到达“CUSTOMER” ，反之亦然。

* * *

1. 自然语言描述拓扑是困难的
2. 自动化脚本 - 根据给定的拓扑生成文字
3. 限制问题为 ： 星形网络 “star networks” (Mondal 等, 2023, p. 193)
    
    - “one router would be attached to a CUSTOMER IP, while the other routers are connected to different ISPs (Figure 4)”
4. “network generator”  只需要 路由器个数作为输入就能描述网络拓扑
5. 两个输入
    
    - “a textual description”  - 提示词
    - “a JSON dictionary for the entire network topology”  - 检查生成的结果是否符合网络拓扑
6. “Local versus Global Policy Prompts?”
    
    - 使用AS路径正则表达式过滤路由 + 拒绝从客户路由器向其他路由器发布ISP前缀
    - 纠正拓扑和语法错误后，以反例包的形式提供反馈时（就像“Minesweeper” 这样的“全局”网络验证器提供的那样），GPT-4在不正确的策略间不断振荡。
    - 在Lightyear[11]中指定本地策略得到了更好的结果，因为它允许我们将验证错误定位到特定路由器和这些路由器中的特定d的“route maps” 。
    - 对比 Minesweeper 和 Lightyear 的区别 - 验证方法
    - 要求GPT-4每次使用一个新的提示词为每个路由器生成配置，为每个路由器指定本地策略。
    - 具体来说，策略是R1应该添加一个特定的“community” 在每个ISP的入口，然后丢弃路由基于这些“community” 在每个ISP的出口
    
    7\. 产生的错误分为三类：
    
    - “Syntax errors”
    - “Topology errors”
        
        - GPT-4错误声明或遗漏BGP邻居或忘记宣布某些网络
        - “an automated "topology verifier"”  -  系统地解析所有以太网接口
        - 将配置中的BGP邻居和网络声明与JSON字典中列出的网络体系结构进行匹配
        - 然后指出所有缺失的声明和拓扑不一致问题
    - “Semantic errors / Policy errors”
        
        - GPT-4生成的配置不遵循预期的本地策略。
        - 使用Batfish“搜索路由策略”（“Search Route Policies” ）进行验证。
        - 存在语义错误，Batfish会生成一个没有遵循本地策略的示例
        - 在新的提示词中，将这个示例反馈给GPT4
    
    * * *
    
    1. 所有错误都被纠正
    2. 使用Batfish作为最后一步来模拟整个BGP通信（以确保满足全局策略）
    3. 尽管可以使用Lightyear[11]的证明技术来确保局部策略隐含全局策略

### “Experience and Results”

1. 由于一些GPT-4错误更常见，提供了一个IIP（初始指令提示符）
    
    - “CLI prompts”  - 要求生成 .cfg 文件
    - “Wrong keywords”  ：
        
        - ‘ exit ’， ‘ end ’， ‘ configure terminal ’， ‘ ip routing ’， ‘ write ’， ‘ hostname ’和‘ conf ’。
        - GPT4把其中一些放在错误的位置
        - 指示它不要使用这些关键字
    - “Match Community”
        
        - GPT-4有时会尝试直接匹配“community value” ，这是不正确的。
        - 相反，必须声明包含“community value” 的“community list” ，并且“route-map” 必须与“community list”匹配。
        - IIP - 告诉GPT-4在“community list”上定义和匹配。
    - “Adding Communities”
        
        - 上述配置错误地将路由中所有现有的“ommunities” 替换为“community” 100:1。
        - 添加了一个IIP，说明在向路由添加community时应该始终使用“additive”关键字。
2. “two egregious cases where human intervention干预  is needed”
    
    - “Placing neighbor commands in the wrong location”
        
        - “BGP” 的配置文件中，给接口定义“route-map” 时，必须将其放在 router bgp  block内的接口 中。
        - 有时GPT-4定义了一个route-map，然后将它与“router bgp”块之外的接口关联起来。
        - Batfish捕获了这个语法错误，但是输出的信息不足以让GPT-4修复这个问题。
    - “AND/OR Semantics in match statements”
        
        - “asked GPT-4 to generate a config for R1 that would add a specific community to every route incoming from R2”
        - 要求它在连接R1到R2−R6的接口的出接口上过滤包含此community的路由
        - GPT-4在入接口添加了正确的community，但在出接口错误地使用AND语义过滤路由
        - 需要人工提示来要求GPT-4在单独的“route-map” 节中声明每个匹配语句。
3. “Leverage”  “2 human prompts and 12 automated prompts”  - 6X
    
    * * *
    

# 5. Previous Work

1. 程序生成 “AlphaCode [10], CoPilot [7], Codex [4] and Jigsaw 等
    
    - “they do not pair the synthesizer with verifiers”
    - “Alphacode”  ： 不是使用通用的 LLM ，而是使用一个精心挑选的程序数据集
    - “Codex” ：“repeated sampling” 反复抽样，而不是修正
    - “Jigsaw” ：“automatic syntax correction via AST-to-AST transformations”
    - “CoPilot” ：“suggest invariants”  但是没有 “an axiomatic proof”
    - 这些都没有解决两个基本问题
        
        - “how to use a specification”
        - “how to provide localized feedback”
2. “use of ChatGPT with the Kani Rust verifier” （Kani Rust Verifier Blog. Writing Code with ChatGPT? Improve it with Kani. [https://model-checking.github.io/kani-verifier-blog/2023/05/01/ writing-code-with-chatgpt-improve-it-with-kani.html,](https://model-checking.github.io/kani-verifier-blog/2023/05/01/writing-code-with-chatgpt-improve-it-with-kani.html) 2023.）- “closest”  
    
    - 巧妙处理了规范问题
    - “by focusing on program transformations for which the source program is the specification.”
    - “do not use modularity or local specifications.”
    - “does not do prompt programming”
    - “the user always manually switches between the verifier and the LLM, precluding possible leverage.”

* * *

# 6. 总结

“Our experiments are very preliminary初步的 but suggest:”

1. “Ramanujam Effect” ：没有帮助的情况下，GPT4会产生导致网络崩溃的一些简单问题
2. “Verified Prompt Programming” ：使用验证器和人工结合的方式进行自动更正。“Modular verification” 提供的反馈对LLM至关重要
3. “Local versus Global Specifications”
    
    - LLM的搜索空间很大，这增加了它无法正确完成基于全局规范的配置生成任务的可能性
    - 相反，用户需要决定和描述每个节点在满足全局规范方面所扮演的“角色”，并将此信息提供给LLM。

总结： 需要在更复杂的用例中进行更深入的测试。GPT-4能否在不干扰现有已验证策略的情况下增量地添加新策略？虽然我们的论文是在网络配置的背景下设置的，但愿景，定义（例如，“leverage” ）和教训（例如，对可操作的本地反馈的需求，模块化，人性“humanizers” 化和iip）似乎对生成“synthesize” 其他程序更有用。